2021-11-08 21:28:20,502 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2021-11-08 21:28:25,595 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2021-11-08 21:28:25,918 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.4.2
TS Home: /Users/abhisheksingh/opt/anaconda3/envs/torchserve/lib/python3.8/site-packages
Current directory: /Users/abhisheksingh/Desktop/projects/torchserve
Temp directory: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/abhisheksingh/opt/anaconda3/envs/torchserve/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/abhisheksingh/Desktop/projects/torchserve/model_store
Initial Models: mnist=mnist.mar
Log dir: /Users/abhisheksingh/Desktop/projects/torchserve/logs
Metrics dir: /Users/abhisheksingh/Desktop/projects/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/abhisheksingh/Desktop/projects/torchserve/model_store
Model config: N/A
2021-11-08 21:28:25,938 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: mnist.mar
2021-11-08 21:28:25,944 [WARN ] main org.pytorch.serve.ModelServer - Failed to load model: mnist.mar
org.pytorch.serve.archive.model.ModelNotFoundException: Model not found at: mnist.mar
	at org.pytorch.serve.archive.model.ModelArchive.downloadModel(ModelArchive.java:75)
	at org.pytorch.serve.wlm.ModelManager.createModelArchive(ModelManager.java:167)
	at org.pytorch.serve.wlm.ModelManager.registerModel(ModelManager.java:133)
	at org.pytorch.serve.ModelServer.initModelStore(ModelServer.java:242)
	at org.pytorch.serve.ModelServer.startRESTserver(ModelServer.java:356)
	at org.pytorch.serve.ModelServer.startAndWait(ModelServer.java:117)
	at org.pytorch.serve.ModelServer.main(ModelServer.java:98)
2021-11-08 21:28:25,952 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2021-11-08 21:28:26,054 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2021-11-08 21:28:26,054 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2021-11-08 21:28:26,055 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2021-11-08 21:28:26,055 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2021-11-08 21:28:26,056 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2021-11-08 21:29:34,208 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2021-11-08 21:29:34,209 [INFO ] KQueueEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2021-11-08 21:29:34,209 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2021-11-08 21:29:36,252 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2021-11-08 21:30:39,870 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2021-11-08 21:30:44,958 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2021-11-08 21:30:45,400 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.4.2
TS Home: /Users/abhisheksingh/opt/anaconda3/envs/torchserve/lib/python3.8/site-packages
Current directory: /Users/abhisheksingh/Desktop/projects/torchserve
Temp directory: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/abhisheksingh/opt/anaconda3/envs/torchserve/bin/python
Config file: logs/config/20211108212934210-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/abhisheksingh/Desktop/projects/torchserve/model_store
Initial Models: smoke=smokemodel.mar
Log dir: /Users/abhisheksingh/Desktop/projects/torchserve/logs
Metrics dir: /Users/abhisheksingh/Desktop/projects/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/abhisheksingh/Desktop/projects/torchserve/model_store
Model config: N/A
2021-11-08 21:30:45,414 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20211108212934210-shutdown.cfg",
  "modelCount": 0,
  "created": 1636435774210,
  "models": {}
}
2021-11-08 21:30:45,422 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20211108212934210-shutdown.cfg
2021-11-08 21:30:45,423 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20211108212934210-shutdown.cfg validated successfully
2021-11-08 21:30:45,423 [WARN ] main org.pytorch.serve.snapshot.SnapshotManager - Model snapshot is empty. Starting TorchServe without initial models.
2021-11-08 21:30:45,427 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2021-11-08 21:30:45,506 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2021-11-08 21:30:45,506 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2021-11-08 21:30:45,507 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2021-11-08 21:30:45,507 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2021-11-08 21:30:45,508 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2021-11-08 21:33:58,479 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2021-11-08 21:33:58,480 [INFO ] KQueueEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2021-11-08 21:33:58,480 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2021-11-08 21:34:00,520 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2021-11-08 21:44:39,869 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2021-11-08 21:44:44,956 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2021-11-08 21:44:45,606 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.4.2
TS Home: /Users/abhisheksingh/opt/anaconda3/envs/torchserve/lib/python3.8/site-packages
Current directory: /Users/abhisheksingh/Desktop/projects/torchserve
Temp directory: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/abhisheksingh/opt/anaconda3/envs/torchserve/bin/python
Config file: logs/config/20211108213358480-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/abhisheksingh/Desktop/projects/torchserve/model_store
Initial Models: smoke=modelsmoke.mar
Log dir: /Users/abhisheksingh/Desktop/projects/torchserve/logs
Metrics dir: /Users/abhisheksingh/Desktop/projects/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/abhisheksingh/Desktop/projects/torchserve/model_store
Model config: N/A
2021-11-08 21:44:45,622 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20211108213358480-shutdown.cfg",
  "modelCount": 0,
  "created": 1636436038480,
  "models": {}
}
2021-11-08 21:44:45,633 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20211108213358480-shutdown.cfg
2021-11-08 21:44:45,634 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20211108213358480-shutdown.cfg validated successfully
2021-11-08 21:44:45,634 [WARN ] main org.pytorch.serve.snapshot.SnapshotManager - Model snapshot is empty. Starting TorchServe without initial models.
2021-11-08 21:44:45,640 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2021-11-08 21:44:45,731 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2021-11-08 21:44:45,731 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2021-11-08 21:44:45,731 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2021-11-08 21:44:45,731 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2021-11-08 21:44:45,732 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2021-11-08 21:52:04,167 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2021-11-08 21:52:04,168 [INFO ] KQueueEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2021-11-08 21:52:04,169 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2021-11-08 21:52:06,221 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2021-11-08 21:59:39,072 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2021-11-08 21:59:44,179 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2021-11-08 21:59:44,649 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.4.2
TS Home: /Users/abhisheksingh/opt/anaconda3/envs/torchserve/lib/python3.8/site-packages
Current directory: /Users/abhisheksingh/Desktop/projects/torchserve
Temp directory: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/abhisheksingh/opt/anaconda3/envs/torchserve/bin/python
Config file: logs/config/20211108215204169-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/abhisheksingh/Desktop/projects/torchserve/model_store
Initial Models: smoke=modelsmoke.mar
Log dir: /Users/abhisheksingh/Desktop/projects/torchserve/logs
Metrics dir: /Users/abhisheksingh/Desktop/projects/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/abhisheksingh/Desktop/projects/torchserve/model_store
Model config: N/A
2021-11-08 21:59:44,669 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20211108215204169-shutdown.cfg",
  "modelCount": 0,
  "created": 1636437124169,
  "models": {}
}
2021-11-08 21:59:44,678 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20211108215204169-shutdown.cfg
2021-11-08 21:59:44,679 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20211108215204169-shutdown.cfg validated successfully
2021-11-08 21:59:44,680 [WARN ] main org.pytorch.serve.snapshot.SnapshotManager - Model snapshot is empty. Starting TorchServe without initial models.
2021-11-08 21:59:44,689 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2021-11-08 21:59:44,791 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2021-11-08 21:59:44,791 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2021-11-08 21:59:44,792 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2021-11-08 21:59:44,792 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2021-11-08 21:59:44,792 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2021-11-08 22:02:51,894 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2021-11-08 22:02:51,895 [INFO ] KQueueEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2021-11-08 22:02:51,895 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2021-11-08 22:02:53,936 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2021-11-08 22:08:24,538 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2021-11-08 22:08:25,016 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.4.2
TS Home: /Users/abhisheksingh/opt/anaconda3/envs/torchserve/lib/python3.8/site-packages
Current directory: /Users/abhisheksingh/Desktop/projects/torchserve
Temp directory: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/abhisheksingh/opt/anaconda3/envs/torchserve/bin/python
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /Users/abhisheksingh/Desktop/projects/torchserve/model_store
Initial Models: smoke=modelsmoke.mar
Log dir: /Users/abhisheksingh/Desktop/projects/torchserve/logs
Metrics dir: /Users/abhisheksingh/Desktop/projects/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/abhisheksingh/Desktop/projects/torchserve/model_store
Model config: N/A
2021-11-08 22:08:25,036 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2021-11-08 22:08:25,069 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: modelsmoke.mar
2021-11-08 22:08:26,001 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model smoke
2021-11-08 22:08:26,002 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model smoke
2021-11-08 22:08:26,002 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model smoke loaded.
2021-11-08 22:08:26,002 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: smoke, count: 8
2021-11-08 22:08:26,025 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2021-11-08 22:08:26,178 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2021-11-08 22:08:26,178 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2021-11-08 22:08:26,179 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2021-11-08 22:08:26,179 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2021-11-08 22:08:26,180 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2021-11-08 22:08:26,680 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2021-11-08 22:08:29,579 [DEBUG] W-9002-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-smoke_1.0 State change null -> WORKER_STARTED
2021-11-08 22:08:29,579 [DEBUG] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-smoke_1.0 State change null -> WORKER_STARTED
2021-11-08 22:08:29,579 [DEBUG] W-9001-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-smoke_1.0 State change null -> WORKER_STARTED
2021-11-08 22:08:29,579 [DEBUG] W-9003-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-smoke_1.0 State change null -> WORKER_STARTED
2021-11-08 22:08:29,579 [DEBUG] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-smoke_1.0 State change null -> WORKER_STARTED
2021-11-08 22:08:29,579 [DEBUG] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-smoke_1.0 State change null -> WORKER_STARTED
2021-11-08 22:08:29,579 [DEBUG] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-smoke_1.0 State change null -> WORKER_STARTED
2021-11-08 22:08:29,593 [DEBUG] W-9004-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-smoke_1.0 State change null -> WORKER_STARTED
2021-11-08 22:08:29,603 [INFO ] W-9002-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T//.ts.sock.9002
2021-11-08 22:08:29,603 [INFO ] W-9004-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T//.ts.sock.9004
2021-11-08 22:08:29,603 [INFO ] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T//.ts.sock.9006
2021-11-08 22:08:29,603 [INFO ] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T//.ts.sock.9000
2021-11-08 22:08:29,603 [INFO ] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T//.ts.sock.9007
2021-11-08 22:08:29,603 [INFO ] W-9001-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T//.ts.sock.9001
2021-11-08 22:08:29,603 [INFO ] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T//.ts.sock.9005
2021-11-08 22:08:29,603 [INFO ] W-9003-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T//.ts.sock.9003
2021-11-08 22:08:31,849 [INFO ] W-9004-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2052
2021-11-08 22:08:31,849 [INFO ] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2045
2021-11-08 22:08:31,849 [INFO ] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2053
2021-11-08 22:08:31,849 [INFO ] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2047
2021-11-08 22:08:31,849 [INFO ] W-9002-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2057
2021-11-08 22:08:31,849 [INFO ] W-9001-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2061
2021-11-08 22:08:31,849 [INFO ] W-9003-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2046
2021-11-08 22:08:31,849 [INFO ] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2048
2021-11-08 22:08:31,850 [DEBUG] W-9002-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-smoke_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2021-11-08 22:08:31,850 [DEBUG] W-9003-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-smoke_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2021-11-08 22:08:31,850 [DEBUG] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-smoke_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2021-11-08 22:08:31,850 [DEBUG] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-smoke_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2021-11-08 22:08:31,850 [DEBUG] W-9001-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-smoke_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2021-11-08 22:08:31,849 [DEBUG] W-9004-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-smoke_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2021-11-08 22:08:31,850 [DEBUG] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-smoke_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2021-11-08 22:08:31,854 [DEBUG] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-smoke_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2021-11-08 22:09:44,476 [INFO ] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 334
2021-11-08 22:09:44,477 [DEBUG] W-9007-smoke_1.0 org.pytorch.serve.job.Job - Waiting time ns: 153454, Backend time ns: 336129704
2021-11-08 22:09:47,173 [INFO ] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 214
2021-11-08 22:09:47,173 [DEBUG] W-9005-smoke_1.0 org.pytorch.serve.job.Job - Waiting time ns: 242493, Backend time ns: 214871142
2021-11-08 22:09:55,399 [INFO ] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 204
2021-11-08 22:09:55,399 [DEBUG] W-9006-smoke_1.0 org.pytorch.serve.job.Job - Waiting time ns: 99215, Backend time ns: 205401130
2021-11-08 22:11:47,945 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2021-11-08 22:11:47,945 [INFO ] KQueueEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2021-11-08 22:11:47,945 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2021-11-08 22:11:49,984 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2021-11-08 22:11:49,996 [INFO ] Thread-0 org.pytorch.serve.ModelServer - Unregistering model smoke version 1.0
2021-11-08 22:11:49,997 [DEBUG] Thread-0 org.pytorch.serve.wlm.ModelVersionedRefs - Removed model: smoke version: 1.0
2021-11-08 22:11:49,997 [DEBUG] Thread-0 org.pytorch.serve.wlm.WorkerThread - W-9007-smoke_1.0 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2021-11-08 22:11:49,997 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-smoke_1.0-stderr
2021-11-08 22:11:49,997 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-smoke_1.0-stdout
2021-11-08 22:11:49,997 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_SCALED_DOWN
2021-11-08 22:11:49,997 [DEBUG] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2021-11-08 22:11:49,998 [DEBUG] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2021-11-08 22:11:50,011 [INFO ] W-9007-smoke_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-smoke_1.0-stdout
2021-11-08 22:11:50,011 [DEBUG] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-smoke_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2021-11-08 22:11:50,011 [INFO ] W-9007-smoke_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-smoke_1.0-stderr
2021-11-08 22:11:50,011 [WARN ] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-smoke_1.0-stderr
2021-11-08 22:11:50,012 [WARN ] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-smoke_1.0-stdout
2021-11-08 22:11:50,012 [DEBUG] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2021-11-08 22:11:50,016 [DEBUG] Thread-0 org.pytorch.serve.wlm.WorkerThread - W-9006-smoke_1.0 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2021-11-08 22:11:50,017 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-smoke_1.0-stderr
2021-11-08 22:11:50,017 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-smoke_1.0-stdout
2021-11-08 22:11:50,017 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_SCALED_DOWN
2021-11-08 22:11:50,017 [DEBUG] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2021-11-08 22:11:50,017 [DEBUG] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2021-11-08 22:11:50,017 [DEBUG] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-smoke_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2021-11-08 22:11:50,018 [INFO ] W-9006-smoke_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-smoke_1.0-stdout
2021-11-08 22:11:50,018 [INFO ] W-9006-smoke_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-smoke_1.0-stderr
2021-11-08 22:11:50,018 [WARN ] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-smoke_1.0-stderr
2021-11-08 22:11:50,018 [WARN ] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-smoke_1.0-stdout
2021-11-08 22:11:50,018 [DEBUG] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2021-11-08 22:11:50,034 [DEBUG] Thread-0 org.pytorch.serve.wlm.WorkerThread - W-9005-smoke_1.0 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2021-11-08 22:11:50,039 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-smoke_1.0-stderr
2021-11-08 22:11:50,039 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-smoke_1.0-stdout
2021-11-08 22:11:50,039 [DEBUG] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2021-11-08 22:11:50,039 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_SCALED_DOWN
2021-11-08 22:11:50,042 [INFO ] W-9005-smoke_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-smoke_1.0-stdout
2021-11-08 22:11:50,040 [DEBUG] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2021-11-08 22:11:50,045 [DEBUG] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-smoke_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2021-11-08 22:11:50,046 [INFO ] W-9005-smoke_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-smoke_1.0-stderr
2021-11-08 22:11:50,047 [WARN ] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-smoke_1.0-stderr
2021-11-08 22:11:50,048 [WARN ] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-smoke_1.0-stdout
2021-11-08 22:11:50,049 [DEBUG] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2021-11-08 22:11:50,054 [DEBUG] Thread-0 org.pytorch.serve.wlm.WorkerThread - W-9004-smoke_1.0 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2021-11-08 22:11:50,054 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-smoke_1.0-stderr
2021-11-08 22:11:50,054 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-smoke_1.0-stdout
2021-11-08 22:11:50,054 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_SCALED_DOWN
2021-11-08 22:11:50,054 [DEBUG] W-9004-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2021-11-08 22:11:50,055 [DEBUG] W-9004-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2021-11-08 22:11:50,055 [DEBUG] W-9004-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-smoke_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2021-11-08 22:11:50,057 [INFO ] W-9004-smoke_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-smoke_1.0-stdout
2021-11-08 22:11:50,060 [WARN ] W-9004-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-smoke_1.0-stderr
2021-11-08 22:11:50,061 [INFO ] W-9004-smoke_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-smoke_1.0-stderr
2021-11-08 22:11:50,065 [DEBUG] Thread-0 org.pytorch.serve.wlm.WorkerThread - W-9003-smoke_1.0 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2021-11-08 22:11:50,092 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-smoke_1.0-stderr
2021-11-08 22:11:50,092 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-smoke_1.0-stdout
2021-11-08 22:11:50,092 [WARN ] W-9004-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-smoke_1.0-stdout
2021-11-08 22:11:50,093 [DEBUG] W-9004-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2021-11-08 22:11:50,094 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_SCALED_DOWN
2021-11-08 22:11:50,094 [DEBUG] W-9003-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2021-11-08 22:11:50,097 [DEBUG] W-9003-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2021-11-08 22:11:50,097 [DEBUG] W-9003-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-smoke_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2021-11-08 22:11:50,098 [INFO ] W-9003-smoke_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-smoke_1.0-stdout
2021-11-08 22:11:50,098 [INFO ] W-9003-smoke_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-smoke_1.0-stderr
2021-11-08 22:11:50,098 [WARN ] W-9003-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-smoke_1.0-stderr
2021-11-08 22:11:50,098 [WARN ] W-9003-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-smoke_1.0-stdout
2021-11-08 22:11:50,098 [DEBUG] W-9003-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2021-11-08 22:11:50,102 [DEBUG] Thread-0 org.pytorch.serve.wlm.WorkerThread - W-9002-smoke_1.0 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2021-11-08 22:11:50,102 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-smoke_1.0-stderr
2021-11-08 22:11:50,102 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-smoke_1.0-stdout
2021-11-08 22:11:50,102 [DEBUG] W-9002-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2021-11-08 22:11:50,103 [DEBUG] W-9002-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2021-11-08 22:11:50,103 [DEBUG] W-9002-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-smoke_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2021-11-08 22:11:50,103 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_SCALED_DOWN
2021-11-08 22:11:50,103 [INFO ] W-9002-smoke_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-smoke_1.0-stdout
2021-11-08 22:11:50,103 [INFO ] W-9002-smoke_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-smoke_1.0-stderr
2021-11-08 22:11:50,104 [WARN ] W-9002-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-smoke_1.0-stderr
2021-11-08 22:11:50,114 [WARN ] W-9002-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-smoke_1.0-stdout
2021-11-08 22:11:50,114 [DEBUG] W-9002-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2021-11-08 22:11:50,118 [DEBUG] Thread-0 org.pytorch.serve.wlm.WorkerThread - W-9001-smoke_1.0 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2021-11-08 22:11:50,118 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-smoke_1.0-stderr
2021-11-08 22:11:50,118 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-smoke_1.0-stdout
2021-11-08 22:11:50,119 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_SCALED_DOWN
2021-11-08 22:11:50,167 [INFO ] W-9001-smoke_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-smoke_1.0-stdout
2021-11-08 22:11:50,167 [DEBUG] W-9001-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2021-11-08 22:11:50,167 [DEBUG] W-9001-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2021-11-08 22:11:50,168 [DEBUG] W-9001-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-smoke_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2021-11-08 22:11:50,168 [INFO ] W-9001-smoke_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-smoke_1.0-stderr
2021-11-08 22:11:50,168 [WARN ] W-9001-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-smoke_1.0-stderr
2021-11-08 22:11:50,186 [DEBUG] Thread-0 org.pytorch.serve.wlm.WorkerThread - W-9000-smoke_1.0 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2021-11-08 22:11:50,211 [WARN ] W-9001-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-smoke_1.0-stdout
2021-11-08 22:11:50,211 [DEBUG] W-9001-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2021-11-08 22:11:50,211 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-smoke_1.0-stderr
2021-11-08 22:11:50,211 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-smoke_1.0-stdout
2021-11-08 22:11:50,211 [DEBUG] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2021-11-08 22:11:50,212 [DEBUG] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2021-11-08 22:11:50,212 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_SCALED_DOWN
2021-11-08 22:11:50,217 [DEBUG] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-smoke_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2021-11-08 22:11:50,217 [INFO ] W-9000-smoke_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-smoke_1.0-stdout
2021-11-08 22:11:50,217 [WARN ] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-smoke_1.0-stderr
2021-11-08 22:11:50,217 [INFO ] W-9000-smoke_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-smoke_1.0-stderr
2021-11-08 22:11:50,217 [WARN ] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-smoke_1.0-stdout
2021-11-08 22:11:50,217 [DEBUG] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2021-11-08 22:11:50,222 [INFO ] Thread-0 org.pytorch.serve.wlm.ModelManager - Model smoke unregistered.
2021-11-08 22:18:37,972 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2021-11-08 22:18:38,471 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.4.2
TS Home: /Users/abhisheksingh/opt/anaconda3/envs/torchserve/lib/python3.8/site-packages
Current directory: /Users/abhisheksingh/Desktop/projects/torchserve
Temp directory: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/abhisheksingh/opt/anaconda3/envs/torchserve/bin/python
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /Users/abhisheksingh/Desktop/projects/torchserve/model_store
Initial Models: smoke=modelsmoke.mar
Log dir: /Users/abhisheksingh/Desktop/projects/torchserve/logs
Metrics dir: /Users/abhisheksingh/Desktop/projects/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/abhisheksingh/Desktop/projects/torchserve/model_store
Model config: N/A
2021-11-08 22:18:38,489 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2021-11-08 22:18:38,535 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: modelsmoke.mar
2021-11-08 22:18:39,603 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model smoke
2021-11-08 22:18:39,603 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model smoke
2021-11-08 22:18:39,603 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model smoke loaded.
2021-11-08 22:18:39,603 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: smoke, count: 8
2021-11-08 22:18:39,631 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2021-11-08 22:18:39,871 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2021-11-08 22:18:39,871 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2021-11-08 22:18:39,872 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2021-11-08 22:18:39,872 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2021-11-08 22:18:39,873 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2021-11-08 22:18:40,288 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2021-11-08 22:18:42,896 [DEBUG] W-9001-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-smoke_1.0 State change null -> WORKER_STARTED
2021-11-08 22:18:42,896 [DEBUG] W-9002-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-smoke_1.0 State change null -> WORKER_STARTED
2021-11-08 22:18:42,896 [DEBUG] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-smoke_1.0 State change null -> WORKER_STARTED
2021-11-08 22:18:42,896 [DEBUG] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-smoke_1.0 State change null -> WORKER_STARTED
2021-11-08 22:18:42,896 [DEBUG] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-smoke_1.0 State change null -> WORKER_STARTED
2021-11-08 22:18:42,896 [DEBUG] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-smoke_1.0 State change null -> WORKER_STARTED
2021-11-08 22:18:42,897 [DEBUG] W-9004-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-smoke_1.0 State change null -> WORKER_STARTED
2021-11-08 22:18:42,896 [DEBUG] W-9003-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-smoke_1.0 State change null -> WORKER_STARTED
2021-11-08 22:18:42,903 [INFO ] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T//.ts.sock.9005
2021-11-08 22:18:42,903 [INFO ] W-9003-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T//.ts.sock.9003
2021-11-08 22:18:42,903 [INFO ] W-9002-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T//.ts.sock.9002
2021-11-08 22:18:42,903 [INFO ] W-9004-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T//.ts.sock.9004
2021-11-08 22:18:42,903 [INFO ] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T//.ts.sock.9000
2021-11-08 22:18:42,903 [INFO ] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T//.ts.sock.9007
2021-11-08 22:18:42,903 [INFO ] W-9001-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T//.ts.sock.9001
2021-11-08 22:18:42,903 [INFO ] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/v7/xnn9tnl54vl_ykz9gplc3swc0000gn/T//.ts.sock.9006
2021-11-08 22:18:44,516 [INFO ] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1420
2021-11-08 22:18:44,516 [INFO ] W-9002-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1418
2021-11-08 22:18:44,516 [INFO ] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1421
2021-11-08 22:18:44,516 [INFO ] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1414
2021-11-08 22:18:44,516 [DEBUG] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-smoke_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2021-11-08 22:18:44,516 [DEBUG] W-9002-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-smoke_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2021-11-08 22:18:44,516 [DEBUG] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-smoke_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2021-11-08 22:18:44,516 [DEBUG] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-smoke_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2021-11-08 22:18:44,516 [INFO ] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1414
2021-11-08 22:18:44,517 [DEBUG] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-smoke_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2021-11-08 22:18:44,517 [INFO ] W-9003-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1412
2021-11-08 22:18:44,517 [DEBUG] W-9003-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-smoke_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2021-11-08 22:18:44,518 [INFO ] W-9001-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1423
2021-11-08 22:18:44,518 [DEBUG] W-9001-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-smoke_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2021-11-08 22:18:44,519 [INFO ] W-9004-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1417
2021-11-08 22:18:44,519 [DEBUG] W-9004-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-smoke_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2021-11-08 22:19:07,936 [INFO ] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 284
2021-11-08 22:19:07,938 [DEBUG] W-9007-smoke_1.0 org.pytorch.serve.job.Job - Waiting time ns: 118060, Backend time ns: 287085764
2021-11-08 22:19:13,018 [INFO ] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 210
2021-11-08 22:19:13,019 [DEBUG] W-9000-smoke_1.0 org.pytorch.serve.job.Job - Waiting time ns: 193447, Backend time ns: 211619428
2021-11-08 22:21:32,458 [INFO ] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 218
2021-11-08 22:21:32,460 [DEBUG] W-9005-smoke_1.0 org.pytorch.serve.job.Job - Waiting time ns: 115072, Backend time ns: 220307776
2021-11-08 22:23:28,003 [INFO ] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3367
2021-11-08 22:23:28,005 [DEBUG] W-9006-smoke_1.0 org.pytorch.serve.job.Job - Waiting time ns: 572945, Backend time ns: 3402883030
2021-11-08 22:24:17,709 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2021-11-08 22:24:17,710 [INFO ] KQueueEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2021-11-08 22:24:17,710 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2021-11-08 22:24:19,760 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2021-11-08 22:24:19,772 [INFO ] Thread-0 org.pytorch.serve.ModelServer - Unregistering model smoke version 1.0
2021-11-08 22:24:19,772 [DEBUG] Thread-0 org.pytorch.serve.wlm.ModelVersionedRefs - Removed model: smoke version: 1.0
2021-11-08 22:24:19,772 [DEBUG] Thread-0 org.pytorch.serve.wlm.WorkerThread - W-9007-smoke_1.0 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2021-11-08 22:24:19,772 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-smoke_1.0-stderr
2021-11-08 22:24:19,772 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-smoke_1.0-stdout
2021-11-08 22:24:19,773 [DEBUG] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2021-11-08 22:24:19,773 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_SCALED_DOWN
2021-11-08 22:24:19,773 [DEBUG] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2021-11-08 22:24:19,781 [DEBUG] Thread-0 org.pytorch.serve.wlm.WorkerThread - W-9006-smoke_1.0 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2021-11-08 22:24:19,786 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-smoke_1.0-stderr
2021-11-08 22:24:19,786 [INFO ] W-9007-smoke_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-smoke_1.0-stdout
2021-11-08 22:24:19,786 [DEBUG] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-smoke_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2021-11-08 22:24:19,786 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-smoke_1.0-stdout
2021-11-08 22:24:19,786 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_SCALED_DOWN
2021-11-08 22:24:19,787 [DEBUG] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2021-11-08 22:24:19,787 [DEBUG] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2021-11-08 22:24:19,787 [INFO ] W-9006-smoke_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-smoke_1.0-stdout
2021-11-08 22:24:19,787 [INFO ] W-9007-smoke_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-smoke_1.0-stderr
2021-11-08 22:24:19,787 [WARN ] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-smoke_1.0-stderr
2021-11-08 22:24:19,787 [DEBUG] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-smoke_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2021-11-08 22:24:19,787 [WARN ] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-smoke_1.0-stdout
2021-11-08 22:24:19,787 [DEBUG] W-9007-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2021-11-08 22:24:19,789 [WARN ] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-smoke_1.0-stderr
2021-11-08 22:24:19,789 [INFO ] W-9006-smoke_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-smoke_1.0-stderr
2021-11-08 22:24:19,790 [WARN ] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-smoke_1.0-stdout
2021-11-08 22:24:19,790 [DEBUG] W-9006-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2021-11-08 22:24:19,798 [DEBUG] Thread-0 org.pytorch.serve.wlm.WorkerThread - W-9005-smoke_1.0 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2021-11-08 22:24:19,798 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-smoke_1.0-stderr
2021-11-08 22:24:19,798 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-smoke_1.0-stdout
2021-11-08 22:24:19,799 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_SCALED_DOWN
2021-11-08 22:24:19,799 [DEBUG] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2021-11-08 22:24:19,799 [DEBUG] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2021-11-08 22:24:19,799 [DEBUG] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-smoke_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2021-11-08 22:24:19,801 [INFO ] W-9005-smoke_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-smoke_1.0-stdout
2021-11-08 22:24:19,803 [INFO ] W-9005-smoke_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-smoke_1.0-stderr
2021-11-08 22:24:19,803 [WARN ] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-smoke_1.0-stderr
2021-11-08 22:24:19,813 [DEBUG] Thread-0 org.pytorch.serve.wlm.WorkerThread - W-9004-smoke_1.0 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2021-11-08 22:24:19,819 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-smoke_1.0-stderr
2021-11-08 22:24:19,819 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-smoke_1.0-stdout
2021-11-08 22:24:19,819 [WARN ] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-smoke_1.0-stdout
2021-11-08 22:24:19,819 [DEBUG] W-9005-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2021-11-08 22:24:19,820 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_SCALED_DOWN
2021-11-08 22:24:19,826 [DEBUG] W-9004-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2021-11-08 22:24:19,826 [DEBUG] W-9004-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2021-11-08 22:24:19,826 [DEBUG] W-9004-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-smoke_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2021-11-08 22:24:19,831 [INFO ] W-9004-smoke_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-smoke_1.0-stdout
2021-11-08 22:24:19,833 [WARN ] W-9004-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-smoke_1.0-stderr
2021-11-08 22:24:19,833 [WARN ] W-9004-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-smoke_1.0-stdout
2021-11-08 22:24:19,833 [INFO ] W-9004-smoke_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-smoke_1.0-stderr
2021-11-08 22:24:19,840 [DEBUG] Thread-0 org.pytorch.serve.wlm.WorkerThread - W-9003-smoke_1.0 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2021-11-08 22:24:19,860 [DEBUG] W-9004-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2021-11-08 22:24:19,861 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-smoke_1.0-stderr
2021-11-08 22:24:19,861 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-smoke_1.0-stdout
2021-11-08 22:24:19,863 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_SCALED_DOWN
2021-11-08 22:24:19,864 [DEBUG] W-9003-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2021-11-08 22:24:19,864 [DEBUG] W-9003-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2021-11-08 22:24:19,871 [DEBUG] W-9003-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-smoke_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2021-11-08 22:24:19,874 [INFO ] W-9003-smoke_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-smoke_1.0-stdout
2021-11-08 22:24:19,875 [WARN ] W-9003-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-smoke_1.0-stderr
2021-11-08 22:24:19,875 [WARN ] W-9003-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-smoke_1.0-stdout
2021-11-08 22:24:19,875 [DEBUG] W-9003-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2021-11-08 22:24:19,875 [INFO ] W-9003-smoke_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-smoke_1.0-stderr
2021-11-08 22:24:19,885 [DEBUG] Thread-0 org.pytorch.serve.wlm.WorkerThread - W-9002-smoke_1.0 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2021-11-08 22:24:19,887 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-smoke_1.0-stderr
2021-11-08 22:24:19,887 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-smoke_1.0-stdout
2021-11-08 22:24:19,888 [DEBUG] W-9002-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2021-11-08 22:24:19,889 [DEBUG] W-9002-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2021-11-08 22:24:19,889 [DEBUG] W-9002-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-smoke_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2021-11-08 22:24:19,888 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_SCALED_DOWN
2021-11-08 22:24:19,895 [INFO ] W-9002-smoke_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-smoke_1.0-stdout
2021-11-08 22:24:19,897 [WARN ] W-9002-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-smoke_1.0-stderr
2021-11-08 22:24:19,897 [INFO ] W-9002-smoke_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-smoke_1.0-stderr
2021-11-08 22:24:19,909 [DEBUG] Thread-0 org.pytorch.serve.wlm.WorkerThread - W-9001-smoke_1.0 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2021-11-08 22:24:19,920 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-smoke_1.0-stderr
2021-11-08 22:24:19,920 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-smoke_1.0-stdout
2021-11-08 22:24:19,922 [WARN ] W-9002-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-smoke_1.0-stdout
2021-11-08 22:24:19,923 [DEBUG] W-9001-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2021-11-08 22:24:19,923 [DEBUG] W-9001-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2021-11-08 22:24:19,923 [DEBUG] W-9001-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-smoke_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2021-11-08 22:24:19,923 [DEBUG] W-9002-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2021-11-08 22:24:19,923 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_SCALED_DOWN
2021-11-08 22:24:19,928 [INFO ] W-9001-smoke_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-smoke_1.0-stdout
2021-11-08 22:24:19,929 [INFO ] W-9001-smoke_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-smoke_1.0-stderr
2021-11-08 22:24:19,929 [WARN ] W-9001-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-smoke_1.0-stderr
2021-11-08 22:24:19,929 [WARN ] W-9001-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-smoke_1.0-stdout
2021-11-08 22:24:19,929 [DEBUG] W-9001-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2021-11-08 22:24:19,938 [DEBUG] Thread-0 org.pytorch.serve.wlm.WorkerThread - W-9000-smoke_1.0 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2021-11-08 22:24:19,938 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-smoke_1.0-stderr
2021-11-08 22:24:19,938 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-smoke_1.0-stdout
2021-11-08 22:24:19,938 [DEBUG] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2021-11-08 22:24:19,939 [DEBUG] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2021-11-08 22:24:19,939 [DEBUG] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-smoke_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2021-11-08 22:24:19,939 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_SCALED_DOWN
2021-11-08 22:24:19,939 [INFO ] W-9000-smoke_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-smoke_1.0-stdout
2021-11-08 22:24:19,941 [INFO ] W-9000-smoke_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-smoke_1.0-stderr
2021-11-08 22:24:19,941 [WARN ] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-smoke_1.0-stderr
2021-11-08 22:24:19,961 [INFO ] Thread-0 org.pytorch.serve.wlm.ModelManager - Model smoke unregistered.
2021-11-08 22:24:19,978 [WARN ] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-smoke_1.0-stdout
2021-11-08 22:24:19,979 [DEBUG] W-9000-smoke_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
